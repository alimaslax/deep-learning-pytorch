{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bae89e-40f5-4451-bb51-968069a612cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fully Connected Feed Forward Nueral Network\n",
    "\n",
    "These notes are from Harrisons Tutorial linked below:\n",
    "Data - Deep Learning and Neural Networks with Python and Pytorch \n",
    "https://youtu.be/i2yPxY2rOzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be6973e7-a6ba-404e-b82c-b12f907f0007",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mali/dev/jupyter/lib/python3.10/site-packages (1.12.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/mali/dev/jupyter/lib/python3.10/site-packages (0.13.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from torch) (4.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from torchvision) (9.2.0)\r\n",
      "Requirement already satisfied: numpy in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from torchvision) (1.23.1)\r\n",
      "Requirement already satisfied: requests in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from torchvision) (2.28.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from requests->torchvision) (1.26.10)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from requests->torchvision) (2.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from requests->torchvision) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mali/dev/jupyter/lib/python3.10/site-packages (from requests->torchvision) (2022.6.15)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m22.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c4cda8-667a-43b2-b05d-3ad33bb658e5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we are simply importing a balanced & batched training and testing data\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "tests = datasets.MNIST('', train=False, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor()\n",
    "                      ]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(tests, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cdd5b51-b45a-4eae-a9a0-450eb74905da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Fully Connected Neurol Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de520e40-3d13-4ea2-8e63-3778869597ce",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our Nueral Network Class Net Contains:\n",
    "\n",
    "__nn.Linear 4 layers__\n",
    "Parameter 1  :: input size\n",
    "    This is 28 * 28 pixel image (1x784)\n",
    "Parameter 2 :: output size\n",
    "    Number of output Classes\n",
    "    \n",
    "__feed-forward func__\n",
    "x :: image representation as a 1xDIM\n",
    "\n",
    "__relu activation function__\n",
    "output :: (input data) * weights\n",
    "\n",
    "__soft-max eval__\n",
    "Softmax is for multi-class problems, where each thing can only be one class or the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cef3443-7e03-4338-afee-6f74d490d01a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c3efc-9455-4ffe-9ccc-6bbf7ad8caad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "loss_function: calculates \"how far off\" our classifications are from reality\n",
    "Optimizer: adjusts our model's adjustable parameters like the weights, to slowly, over time, fit our data\n",
    "Adam: Adaptive Momentum, is the standard go-to optimizer usually\n",
    "lr: learning rate, range between 0.001 or 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2f9ea1-da92-4957-81cf-91cf229fc47e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6198, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9123a7-895f-4385-ac4d-96ece80ac9bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Grab the features (X) and labels (y) from current batch\n",
    "Zero the gradients (net.zero_grad)\n",
    "Pass the data through the network\n",
    "Calculate the loss\n",
    "Adjust weights in the network with the hopes of decreasing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9aa297d-5325-477a-a148-7f423e113323",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.964\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b40858a-efe4-4568-8814-deaf97c76caf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bb5a6e2-fd67-4432-923e-0d016766b427",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}